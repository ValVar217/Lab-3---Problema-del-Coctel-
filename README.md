<h1 align="center"> Lab-3 - üç∏ Fiesta-de-Coctel- </h1>  

# INTRODUCCI√ìN
La presente Guia/Proyecto tiene como proposito poder analizar distintas fuentes sonoras que se mezclan simulando una "fiesta de Coctel", en donde queremos extraer una se√±al en especifico de nuestro interes dentro de un conjunto de se√±ales que estan superpuestas representando as√≠ el procesamiento de audio, con aplicaciones de reconocimiento de voz, la cancelacion de ruido y la mejora en la calidad del sonido que queremos procesar. Para lograr este objetivo, se emplearon herramientas computacionales que en nuestro caso es Spyder y t√©cnicas de an√°lisis en frecuencia en donde tenemos la Transformada de Fourier Discreta (DFT) y la Transformada R√°pida de Fourier (FFT). Adem√°s de ello, se utilizaron m√©todos de separaci√≥n de fuentes (Audios), como el An√°lisis de Componentes Independientes (ICA) y el Beamforming, esto con el fin de aislar la voz de uno de los tres estudiantes que hicimos parte del proyecto a partir de las se√±ales capturadas por un conjunto de (tres) micr√≥fonos. De esta manera, el presente informe detalla el procedimiento que se siguio en la pr√°ctica, los resultados obtenidos y su an√°lisis de los m√©todos utilizados.   

## Captura de Audio:
Para esto, Tomamos las medidas correspondientes al espacio/salon en donde se ubicarian tanto las personas como tambien los tres microfonos para la toma de audio. En donde las medidas correspondientes al espacio son:   
üîµ Ancho: 181 cm  
üîµ Largo: 146 cm     

![WhatsApp Image 2025-03-07 at 10 55 13 AM](https://github.com/user-attachments/assets/0018fbec-6fe0-44b5-b9ed-eb313485d229)        
  |*Figura 1: Evidencia de medicion del salon para la toma de audio.*|  

Posteriormente, se realizo la ubicacion en lugares estrategicos para el optimo registro del audio para cada uno de los integrantes   

![WhatsApp Image 2025-03-07 at 11 00 52 AM](https://github.com/user-attachments/assets/b61721c3-caa0-4175-949e-316d22924132)    
  |*Figura 2: Ubicaciones de los Tres (3) Microfonos para la toma de audio.*|

Por ultimo, realizamos la medici√≥n de lo que ser√≠a la distancia de cada microfono hasta la persona correspondiente a cada uno (m√°s cercana) para poder hacer un mejor analisis frente a lo que vendrian siendo nuestros resultados 

![WhatsApp Image 2025-03-07 at 11 09 01 AM](https://github.com/user-attachments/assets/feb5865a-0875-4adc-869e-386ed4e6c0fe)      
  |*Figura 3: Distancia de microfono a una fuente sonora (Persona).*|

<h1 align="center"> GUIA DE USUARIO </h1>      

## Analisis y Resultados
Para iniciar, en el encabezado de nuestro codigo podemos encontrar la inicicalizacion de las librerias correspondientes para el optimo funcionamiento del codigo para el procesamiento de se√±ales de audio en la pr√°ctica de laboratorio, se utilizo un conjunto de librer√≠as especializadas en an√°lisis y manipulaci√≥n de se√±ales sonoras: 
```python
import os
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
from pydub import AudioSegment
import noisereduce as nr
 ```
Teniendo en cuenta esta primera parte de codigo, es importante que podamos identificar que funcion tiene cada una de las librerias utilizadas, por lo que tenemos que:  
‚ñ´Ô∏è**os** ‚Üí Nos permite el anejo de archivos y rutas.  
‚ñ´Ô∏è**librosa** ‚Üí Es Para el procesamiento del Audio 
‚ñ´Ô∏è**librosa.display** ‚Üí Se utiliza para el procesamiento de audio.  
‚ñ´Ô∏è**numpy (np)** ‚Üí Se usa para el manejo de arrays y operaciones matem√°ticas.    
‚ñ´Ô∏è**matplotlib.pyplot** ‚Üí Se emplea para la generaci√≥n de gr√°ficos y visualizaci√≥n de datos.   
‚ñ´Ô∏è**soundfile** ‚Üí Facilita la lectura y escritura de archivos de audio.
‚ñ´Ô∏è**pydub** ‚Üí Esta fue utilizada para la conversi√≥n y manipulaci√≥n de archivos de audio en formato de MP3.    
‚ñ´Ô∏è**noisereduce** ‚Üí Ayuda a la reducci√≥n de ruido en las se√±ales de audio, mejorando la calidad de los audios al eliminar sonidos no deseados.    

Posteriormente tenemos una lista llamada "rutas_audios" que almacena las rutas de acceso a los archivos de audio capturados por diferentes micr√≥fonos.
En este caso, se tienen tres archivos en formato MP3 correspondientes a grabaciones realizadas con tres micr√≥fonos, esto se hace con el fin de subir los debidos audios al programa y poder realizar los debidos procedimientos con ellos.
```python  
# Rutas de los archivos de audio
rutas_audios = [
    "C:/Users/Esteban/Videos/PRUEBA/Proyecto predeterminado/MICROFONO 1.mp3",
    "C:/Users/Esteban/Videos/PRUEBA/Proyecto predeterminado/MICROFONO 2.mp3",
    "C:/Users/Esteban/Videos/PRUEBA/Proyecto predeterminado/MICROFONO 3.mp3"
 ```

Para la parte de codigo a continuacion lo que buscamos es la carga del audio en formato MP3, ajustando la frecuencia de muestreo a 44.1 kHz, recorta los primeros 20 segundos y normaliza la se√±al dividi√©ndola por su valor absoluto m√°ximo y su segunda parte es con el fin de calcular la potencia de la se√±al, en donde usamos la **Transformada de Fourier (STFT)** para estimar el ruido de fondo al igual que la **relaci√≥n se√±al-ruido (SNR)** en decibeles:  

```python 
# --- An√°lisis de SNR, reducci√≥n de ruido y gr√°ficas ---
def cargar_audio(ruta, duracion_ms=20000):
    audio = AudioSegment.from_file(ruta, format="mp3")
    audio = audio.set_channels(1).set_frame_rate(44100)
    audio_recortado = audio[:duracion_ms]
    samples = np.array(audio_recortado.get_array_of_samples(), dtype=np.float32)
    samples /= np.max(np.abs(samples))
    return samples  

def calcular_snr(signal):
    power_signal = np.mean(signal ** 2)
    stft = np.abs(librosa.stft(signal))
    noise_magnitude = np.percentile(stft, 10, axis=1)
    power_noise = np.mean(noise_magnitude ** 2)
    snr = -10 * np.log10(power_signal / power_noise)
    return snr, signal
 ```
**Analisis üëÜ**  
La adquisici√≥n de la se√±al se dio por medio de micr√≥fonos de celular por un tiempo de 20segundos teniendo en cuenta que en todos se configur√≥ una frecuencia de muestreo de 44.1 kHz se puede encontrar la configuraci√≥n en audio.set_frame_rate(44100), en cuanto a los niveles de cuantificaci√≥n es importante conocer que el audio proviene de archivos MP3, que ya est√°n comprimidos y cuantizados con una resoluci√≥n espec√≠fica en el momento de cargar el audio con AudioSegment.from_file(), este est√° en un formato de enteros. Luego, al extraer las muestras con np.array(audio_recortado.get_array_of_samples(), dtype=np.float32), las muestras se convierten a valores en punto flotante de 32 bits permiti√©ndonos ajustan el rango de valores entre -1 y 1. El SNR es calculado por medio de las potencias, calcular_snr(signal), se calcula la potencia de la se√±al se eleva al cuadrado cada muestra de la se√±al y luego se saca el promedio, obteniendo la potencia media de la se√±al, para estimar el ruido, se aplica la STFT para obtener el espectro de frecuencias de la se√±al se calcula la potencia promedio del ruido elev√°ndolo al cuadrado y sacando el promedio finalmente el SNR se calcula seg√∫n su ecuaci√≥n.  

Complementando lo anterior, sobre los archivos de audio, se calcula el SNR y grafica la se√±al de audio sin ruido:  

**Calculo del SNR**  
Hay que recordar que la SNR es una m√©trica que cuantifica la calidad de una se√±al en presencia de ruido. Se define como la relaci√≥n entre la potencia de la se√±al √∫til y la potencia del ruido, expresada en decibeles (dB):   

 ![image](https://github.com/user-attachments/assets/ffad5937-9c24-4e59-9ea3-dce5cb31ee35)   

```python  
for ruta in rutas_audios:
    if os.path.exists(ruta):
        audio = cargar_audio(ruta)
        snr, raw_signal = calcular_snr(audio)
        print(f"SNR de {os.path.basename(ruta)} (20s): {snr:.2f} dB")
        start_sample = np.where(np.abs(raw_signal) > 0.01)[0][0]
        raw_signal = raw_signal[start_sample:]
 ``` 
Tambien, genara los caracteristicos que queremos para la visualizacion de nuestras se√±ales correspondientes a cada uno de los audios.
```python 
        plt.figure(figsize=(10, 4))
        plt.plot(raw_signal, color='blue')
        plt.title(f"SE√ëAL RUIDO DE {os.path.basename(ruta)}")
        plt.xlabel("Tiemp(s)")
        plt.ylabel("Muestras")
        plt.grid()
        plt.show()
    else:
        print(f"ERROR: No se encontr√≥ el archivo {ruta}")
 ```
En este punto la se√±al recortada se grafica en el dominio del tiempo utilizando matplotlib. Se establece el color azul y se a√±aden las etiquetas correspondientes a los ejes para facilitar la interpretaci√≥n de la gr√°fica:  
![WhatsApp Image 2025-03-07 at 3 41 08 PM](https://github.com/user-attachments/assets/32373e9b-767f-445f-bac5-735f3523ecb6)      
  |*Figura 4: Se√±al del Microfono 1.*|      
     _________________________________________________________________________________________________
![WhatsApp Image 2025-03-07 at 3 41 08 PM (1)](https://github.com/user-attachments/assets/d295e268-a5a3-4bce-97dc-edd6a5423184)      
  |*Figura 5: Se√±al del Microfono 2.*|         
     _________________________________________________________________________________________________
![WhatsApp Image 2025-03-07 at 3 41 08 PM (2)](https://github.com/user-attachments/assets/63da823f-e528-4469-a2da-9ac1108d23a7)    
  |*Figura 6: Se√±al del Microfono 3.*|     
     _________________________________________________________________________________________________  

Para llevar a cabo el an√°lisis se realiz√≥ en dominio del tiempo generando gr√°ficas del tiempo con respecto a voltaje de cada se√±al, y en el dominio de la frecuencia aplicando la transformada r√°pida de Fourier graficando de igual forma la frecuencia con respecto a su magnitud  
Las se√±ales de audio fueron analizadas de forma independiente con el encontrar informaci√≥n como la potencia que contiene cada una de ellas   
Se realiz√≥ un compilaci√≥n de los tres audios y se calcula la se√±al beamformed esperando aislar la voz de inter√©s.
___________________________________
Para la siguiente parte, lo que se hace es Cargar los archivos de audio, encontrar la amplitud m√°xima entre todas las se√±ales y el tiempo de duraci√≥n m√°ximo:    
```python      
audio_names = ["MICROFONO 1", "MICROFONO 2", "MICROFONO 3"]
plt.figure(figsize=(12, 8))
max_amplitude = 0
max_time = 0
for i, file in enumerate(rutas_audios):
    y, sr = librosa.load(file, sr=None)
    max_amplitude = max(max_amplitude, np.max(np.abs(y)))
    max_time = max(max_time, len(y) / sr) 
 ```

Lo que viene en lo siguiente, es con el proposito de ajustar el dise√±o y muestra las gr√°ficas, definir par√°metros f√≠sicos clave para an√°lisis de se√±ales, especificae las rutas de los archivos de audio de los micr√≥fonos, a su vez asignar etiquetas para los micr√≥fonos, al igual que es para poder establece el directorio de salida para guardar resultados:  
```python    
plt.tight_layout()
plt.show()
# --- Par√°metros ---
distancias = [0, 0.8]  # Distancia entre micr√≥fonos en metros
velocidad_sonido = 343  # Velocidad del sonido en m/s
rutas_audios = [
    "C:/Users/Esteban/Videos/PRUEBA/Proyecto predeterminado/MICROFONO 1.mp3",
    "C:/Users/Esteban/Videos/PRUEBA/Proyecto predeterminado/MICROFONO 2.mp3",
    "C:/Users/Esteban/Videos/PRUEBA/Proyecto predeterminado/MICROFONO 3.mp3"
]
audio_names = ["MICROFONO 1", "MICROFONO 2", "MICROFONO 3"]
output_dir = os.getcwd()  # Guardar archivos en el directorio actual
 ```

Ahora, lo siguiente define una funci√≥n para calcular los retrasos de tiempo entre micr√≥fonos debido a la diferencia en la distancia que recorre el sonido hasta cada micr√≥fono  
```python   
# Funci√≥n para calcular retrasos
def calcular_retraso(distancias, velocidad, sr):
    return tuple(int(d / velocidad * sr) for d in distancias)
 ```
Ahora bien, tenemos la aplicacion de Beamforming a continuacion, pues esta es como un  tipo de tectica que nos permite combinar las se√±ales de varios microfonos para poder mejorar la captacion de la se√±al deseada o de nuestro interes y reducir el ruido:  
```python
# Funci√≥n para aplicar beamforming
def beamforming(signals, delay):
    num_mics = signals.shape[1]
    beamformed_signal = np.zeros(len(signals))
    for i, delay_i in enumerate(delay):
        beamformed_signal += np.roll(signals[:, i], delay_i)
    return beamformed_signal / num_mics
 ```
Hay que tener presente que para ello la funci√≥n beamforming aplica un retraso a cada se√±al y las combina para reforzar las componentes comunes y cancelar el ruido no correlacionado.

```python
# Funci√≥n para calcular SNR
def calcular_snr(se√±al, ruido):
    potencia_se√±al = np.mean(se√±al**2) if np.mean(se√±al**2) > 0 else 1e-10
    potencia_ruido = np.mean(ruido**2) if np.mean(ruido**2) > 0 else 1e-10
    return 10 * np.log10(potencia_se√±al / potencia_ruido)  
 ```


```python
# --- Carga de audios ---
muestras_audios = []
sample_rate = None

for ruta in rutas_audios:
    if os.path.exists(ruta):
        y, sr = librosa.load(ruta, sr=None)
        muestras_audios.append(y)
        if sample_rate is None:
            sample_rate = sr
        elif sample_rate != sr:
            raise ValueError("Las tasas de muestreo de los audios no coinciden.")
    else:
        print(f"ERROR: No se encontr√≥ el archivo {ruta}")
 ```


```python
# Asegurar que todas las se√±ales tengan la misma longitud
longitud_max = max(len(y) for y in muestras_audios)
muestras_audios = [np.pad(y, (0, longitud_max - len(y))) for y in muestras_audios]
 ```


```python
# Convertir a array y calcular retraso
audio_mix = np.vstack(muestras_audios).T
retraso = calcular_retraso(distancias, velocidad_sonido, sample_rate)
 ```


```python
# Aplicar Beamforming
beamformed_signal = beamforming(audio_mix, retraso)
beamformed_signal_denoised = nr.reduce_noise(y=beamformed_signal, sr=sample_rate, stationary=True)
 ```



```python
# Guardar se√±al procesada
output_file_beamformed = os.path.join(output_dir, "se√±al_beamformed.wav")
sf.write(output_file_beamformed, beamformed_signal_denoised, sample_rate)
print(f"Se√±al beamformed guardada en: {output_file_beamformed}") 
 ```


```python
# Aplicar ICA
ica = FastICA(n_components=2)
se√±ales_separadas = ica.fit_transform(audio_mix)
se√±al_ica = se√±ales_separadas[:, 0]
 ```


```python
# Reducir la frecuencia de muestreo de la se√±al ICA
sample_rate_reducido = sample_rate // 2
se√±al_ica_reducida = librosa.resample(se√±al_ica, orig_sr=sample_rate, target_sr=sample_rate_reducido)

output_file_ica = os.path.join(output_dir, "se√±al_ica.wav")
sf.write(output_file_ica, se√±al_ica_reducida, sample_rate_reducido)
print(f"Se√±al ICA guardada en: {output_file_ica}")
 ```


```python
# C√°lculo de SNR
ruido_estimado = audio_mix[:, 1] - audio_mix[:, 0]
snr_beam = calcular_snr(beamformed_signal_denoised, ruido_estimado)
snr_ica = calcular_snr(se√±al_ica, ruido_estimado)
print(Fore.BLUE + f"SNR despu√©s de Beamforming: {snr_beam:.2f} dB")
print(Fore.BLUE + f"SNR despu√©s de ICA: {snr_ica:.2f} dB")
 ```


```python
# --- Graficaci√≥n de se√±ales individuales ---
for i, y in enumerate(muestras_audios):
    plt.figure(figsize=(12, 10))

    # --- Forma de onda ---
    plt.subplot(3, 1, 1)
    librosa.display.waveshow(y, sr=sample_rate)
    plt.title(f"Forma de onda - {audio_names[i]}", fontsize=14)
    plt.xlabel("Tiempo (s)", fontsize=12)
    plt.ylabel("Amplitud (mV)", fontsize=12)

    # --- Espectro de frecuencia ---
    N = len(y)
    T = 1.0 / sample_rate
    fft_values = np.fft.fft(y)
    freqs = np.fft.fftfreq(N, T)[:N // 2]
    fft_values = np.abs(fft_values[:N // 2])

    plt.subplot(3, 1, 2)
    plt.semilogx(freqs, fft_values, color='r')
    plt.title(f"Espectro de Frecuencia - {audio_names[i]}", fontsize=14)
    plt.xlabel("Frecuencia (Hz)", fontsize=12)
    plt.ylabel("Magnitud", fontsize=12)

    # --- Densidad Espectral de Potencia (PSD) ---
    freqs, psd = welch(y, fs=sample_rate, nperseg=1024)

    plt.subplot(3, 1, 3)
    plt.semilogx(freqs, psd, color='g')
    plt.title(f"Densidad Espectral de Potencia - {audio_names[i]}", fontsize=14)
    plt.xlabel("Frecuencia (Hz)", fontsize=12)
    plt.ylabel("PSD (log)", fontsize=12)
    plt.yscale("log")  # Escala logar√≠tmica en el eje Y

    plt.tight_layout(pad=3.0)
    plt.show()
 ```
Teniendo como resultado las siguientes graficas:     

![WhatsApp Image 2025-03-07 at 3 41 09 PM (3)](https://github.com/user-attachments/assets/9e3b8751-a836-4dea-bc36-3e8b347c07cb)    
  |*Figura 7: La forma de onda, el espectro de frecuencia y (PSD) de la Se√±al del Microfono 1.*|   
     _________________________________________________________________________________________________  
![WhatsApp Image 2025-03-07 at 3 41 09 PM (4)](https://github.com/user-attachments/assets/1ef4a4ce-3394-422e-a98e-d50f058965d5)      
  |*Figura 8: La forma de onda, el espectro de frecuencia y (PSD) de la Se√±al del Microfono 2.*|   
     _________________________________________________________________________________________________  
![WhatsApp Image 2025-03-07 at 3 41 09 PM (5)](https://github.com/user-attachments/assets/3b94d994-ca22-4b06-abda-2373fd886319)        
  |*Figura 9: La forma de onda, el espectro de frecuencia y (PSD) de la Se√±al del Microfono 3.*|   
     _________________________________________________________________________________________________

```python
# Graficar comparaci√≥n de se√±ales procesadas
plt.figure(figsize=(12, 6))
plt.plot(beamformed_signal_denoised, label="Se√±al Beamformed", alpha=0.7)
plt.plot(se√±al_ica_reducida, label="Se√±al ICA (Frecuencia Reducida)", alpha=0.7)
plt.title("Comparaci√≥n de Se√±ales Procesadas")
plt.xlabel("Muestras")
plt.ylabel("Amplitud")
plt.legend()
plt.grid()
plt.show()
 ```

# RESULTADOS  
Se evidencia inicialmente la carga de los audios con sus respectivas gr√°ficas en donde podemos observar el tiempo de sonido del vac√≠o y el tiempo en que hay una voz se grafica independiente el sonido vac√≠o de 20 segundos, de esta grafica podemos hallar la potencia de ruido valor para calcular el SNR de cada se√±al del micr√≥fono 1 obtuvimos un SNR de 14.57 dB, micr√≥fono 2 SNR de 8.21dB y el micr√≥fono 3 el SNR es de 10.96dB
Estos resultados son comparados con bibliograf√≠a ya que el SNR que se espera obtener de un micr√≥fono de celular oscila entre 10 a 20 dB, el resultado del micr√≥fono 2 es m√°s bajo de lo normal y asociamos esto a da√±os del micr√≥fono o desactualizaci√≥n debido que la toma fue de un celular un poco m√°s viejo.  

Se prepresenta en la segunda gr√°fica colo rojo  el Espectro de Frecuencia, que muestra la Transformada de Fourier (FFT) de la se√±al en una escala lineal.realizamos el an√°lisis para cada micr√≥fono: Micr√≥fono 1 encontramos que la m√°xima magnitud que presenta es alrededor de 2000 esto debido a la que la voz de la persona sexo femenino es un poco m√°s tenue y la ubicaci√≥n de distancia que ten√≠a del micr√≥fono, el micr√≥fono 2 presenta una magnitud m√°xima cercana a 5000 pero est√° magnitud se mantiene medianamente constante con respecto a las otras se√±ales asociamos esto a qu√© la persona de sexo masculino cuenta con un tono de voz mucho m√°s fuerte con respecto a los otros y mantuvo contante su tono de voz, tambi√©n su distancia con respecto al micr√≥fono, micr√≥fono 3 presenta una magnitud m√°xima de aproximadamente 2500, presenta un pico mucho m√°s alto pero no duradero debido a que fue un golpe moment√°neo que se le realiz√≥ al micr√≥fono, luego de esto mantiene su magnitud entre 1000 y 2500, realizamos la comparaci√≥n con el micr√≥fono 1 e identificamos la importancia de la distancia y ubicaci√≥n de la persona con respecto al micr√≥fono ya que en los dos son personas de sexo femenino pero el micr√≥fono 3 la persona estaba m√°s cerca de este.   

Con respecto al eje X Frecuencia en Hz, escala lineal, representa las frecuencias presentes en la se√±al. La escala es logar√≠tmica, lo que permite visualizar mejor un amplio rango de frecuencia analizando una a una las se√±ales encontramos que Micr√≥fono 1 el espectro muestra picos concentrados en una banda alrededor de los 100 Hz-1 kHz , esto indica que la se√±al captada tiene componentes en ese rango de frecuencias, posiblemente un sonido, no se observan muchas frecuencias altas, lo que sugiere que la se√±al es m√°s limpia o que el micr√≥fono tiene menor sensibilidad en frecuencias m√°s altas.  

El micr√≥fono 2 indica presencia de picos en el rango de 100 Hz a 1 kHz nos brinda informaci√≥n de que el sonido captado tiene componentes dominantes en esta banda, este rango es t√≠pico de voces humanas que fue lo que se midi√≥, este micr√≥fono capt√≥ una se√±al con m√°s energ√≠a en variaciones esto puede deberse a que el micr√≥fono est√© m√°s cerca de la persona o capt√≥ m√°s ruido ambiental, en el micr√≥fono 3 se observa un pico muy marcado en la zona de 100 Hz , lo que indica que esta frecuencia es la m√°s fuerte en la se√±al captada esto sugiere que el micr√≥fono registr√≥ un sonido con un tono grave predominante, que ser√≠a el golpe del que se habl√≥ anteriormente adem√°s del pico dominante, hay varias frecuencias con amplitudes m√°s bajas que se extienden hasta los 3 kHz esto indica que el sonido no es completamente puro este micr√≥fono muestra menos energ√≠a en frecuencias m√°s altas esto puede indicar que capt√≥ una se√±al m√°s enfocada en los tonos graves o que su respuesta en frecuencias altas es menor capt√≥ una se√±al con un tono grave predominante , con un fuerte pico en 100 Hz y algunos arm√≥nicos en el rango de 100 Hz-3 kHz .  

Con respecto a las gr√°ficas de Densidad Espectral de Potencia todas siguen una tendencia descendente a medida que aumenta la frecuencia, la forma de la curva sugiere que hay un filtro natural o una limitaci√≥n en el sistema que aten√∫a las frecuencias m√°s altas analizando regi√≥n de medias frecuencias (10¬≤ - 10¬≥ Hz) evidenciamos que aqu√≠ es donde se observan diferencias m√°s notables ya que en el MICR√ìFONO 1 y MICR√ìFONO 3, la curva muestra una ligera ca√≠da progresiva con peque√±as fluctuaciones mientras que El MICR√ìFONO 2 mantiene una ca√≠da m√°s uniforme y menos oscilaciones. El an√°lisis entre regi√≥n de altas frecuencias (10¬≥ - 10‚Å¥ Hz) se observa una ca√≠da m√°s pronunciada en todos los micr√≥fonos, lo que sugiere una p√©rdida de potencia en altas frecuencias debido a la respuesta del sistema o las caracter√≠sticas del micr√≥fono y El MICR√ìFONO 3 muestra m√°s fluctuaciones en esta regi√≥n antes de la ca√≠da final, cerca de 10‚Å¥ Hz en todos los casos, hay una ca√≠da abrupta que indica el l√≠mite del ancho de banda del sistema. La representaci√≥n logar√≠tmica resalta que la energ√≠a est√° m√°s concentrada en bajas frecuencias y que la atenuaci√≥n en altas frecuencias es un patr√≥n com√∫n en los tres micr√≥fonos. Sin embargo, MICR√ìFONO 2 parece ser el m√°s estable en todo el espectro.  

 

![WhatsApp Image 2025-03-07 at 3 41 26 PM](https://github.com/user-attachments/assets/240332b1-839c-484d-af93-4dfa20bcf374)    
  |*Figura 10: Resultado de Componentes Independientes (ICA) y el Beamforming.*|     



## Licencia 
Open Data Commons Attribution License v1.0

## Temas:
# üì° Procesamiento de Se√±ales  
- Componentes Independientes (ICA)
- El Beamforming

# üîä An√°lisis en Frecuencia  
- Transformada de Fourier Discreta (DFT)
- Transformada R√°pida de Fourier (FFT)

# üñ•Ô∏è C√≥digo e Implementaci√≥n  
- Explicaci√≥n del c√≥digo  
- Ejecuci√≥n y ejemplos  
- Mejoras y optimizaci√≥n  







